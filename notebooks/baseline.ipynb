{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import optuna\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    PrecisionRecallDisplay,\n",
    "    f1_score,\n",
    "    average_precision_score,\n",
    ")\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    ")\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# mlflow ui\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"german-credit-scoring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../data/raw/german_credit_cleaned.csv\").resolve()\n",
    "data = pd.read_csv(data_path)\n",
    "data[\"target\"] = data[\"target\"] == \"good\"\n",
    "data[\"target\"] = data[\"target\"].astype(\"int\")\n",
    "data = data.astype(\n",
    "    {col: \"float64\" for col in data.select_dtypes(include=\"int\").columns}\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\n",
    "    \"checking_acc_status\",\n",
    "    \"cred_hist\",\n",
    "    \"purpose\",\n",
    "    \"saving_acc_bonds\",\n",
    "    \"present_employment_since\",\n",
    "    \"personal_stat_gender\",\n",
    "    \"other_debtors_guarantors\",\n",
    "    \"property\",\n",
    "    \"other_installment_plans\",\n",
    "    \"housing\",\n",
    "    \"job\",\n",
    "    \"telephone\",\n",
    "    \"is_foreign_worker\",\n",
    "]\n",
    "\n",
    "num_cols = [\n",
    "    \"duration\",\n",
    "    \"loan_amt\",\n",
    "    \"installment_rate\",  # 4 unique\n",
    "    \"present_residence_since\",  # 4unique\n",
    "    \"age\",\n",
    "    \"num_curr_loans\",  # 4 unique\n",
    "    \"num_people_provide_maint\",  # 2 unique\n",
    "]\n",
    "\n",
    "encoder_classes = {\n",
    "    \"OneHot\": OneHotEncoder(),\n",
    "    \"Ordinal\": OrdinalEncoder(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"target\"])\n",
    "y = data[\"target\"]\n",
    "X, X_test, y, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(model_name, y_pred, y_pred_proba, y_val):\n",
    "    ap = average_precision_score(y_val, y_pred_proba)\n",
    "    f1 = f1_score(y_val, y_pred, average=\"weighted\")\n",
    "\n",
    "    metrics = {\"AP\": ap, \"F1\": f1}\n",
    "    pr_curve = PrecisionRecallDisplay.from_predictions(\n",
    "        y_val, y_pred_proba, plot_chance_level=True\n",
    "    ).figure_\n",
    "    cm = ConfusionMatrixDisplay.from_predictions(y_val, y_pred).figure_\n",
    "\n",
    "    figures_path = Path(\"../reports/figures\").resolve()\n",
    "\n",
    "    model_dir = figures_path / model_name\n",
    "    model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pr_curve_file = \"pr_curve.png\"\n",
    "    pr_curve_path = model_dir / pr_curve_file\n",
    "    pr_curve.savefig(pr_curve_path)\n",
    "\n",
    "    cm_file = \"confusion_matrix.png\"\n",
    "    cm_path = model_dir / cm_file\n",
    "    cm.savefig(cm_path)\n",
    "    return metrics, model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "params = {\"strategy\": \"most_frequent\"}\n",
    "dc = DummyClassifier(**params)\n",
    "dc.fit(X_train, y_train)\n",
    "\n",
    "y_pred_proba = dc.predict_proba(X_val)[:, 1]\n",
    "y_pred = dc.predict(X_val)\n",
    "\n",
    "metrics, artifacts = get_metrics(\"dummy_classifier\", y_pred, y_pred_proba, y_val)\n",
    "\n",
    "# with mlflow.start_run(run_name=\"dummy_classifier\") as run:\n",
    "#     mlflow.log_params(params)\n",
    "#     mlflow.log_metrics(metrics)\n",
    "#     mlflow.sklearn.log_model(\n",
    "#         sk_model=dc,\n",
    "#         artifact_path=\"dummy_classifier\",\n",
    "#         input_example=X,\n",
    "#         registered_model_name=\"dummy_classifier\",\n",
    "#     )\n",
    "#     mlflow.log_artifacts(artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    penalty = trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\", \"elasticnet\"])\n",
    "    C = trial.suggest_float(\"C\", 0.001, 100, log=True)\n",
    "    solver = trial.suggest_categorical(\n",
    "        \"solver\", [\"liblinear\", \"saga\", \"lbfgs\", \"newton-cg\"]\n",
    "    )\n",
    "    encoder_type = trial.suggest_categorical(\n",
    "        \"encoder_type\", list(encoder_classes.keys())\n",
    "    )\n",
    "    encoder = encoder_classes[encoder_type]\n",
    "\n",
    "    if penalty == \"elasticnet\" and solver not in [\"saga\"]:\n",
    "        return float(\"nan\")\n",
    "    if penalty == \"l1\" and solver not in [\"liblinear\", \"saga\"]:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    l1_ratio = None\n",
    "    if penalty == \"elasticnet\":\n",
    "        l1_ratio = trial.suggest_float(\"l1_ratio\", 0.0001, 1.0, log=True)\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"scaler\", StandardScaler(), num_cols),\n",
    "            (\"encoder\", encoder, cat_cols),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        penalty=penalty,\n",
    "        C=C,\n",
    "        solver=solver,\n",
    "        random_state=42,\n",
    "        l1_ratio=l1_ratio,\n",
    "        max_iter=1000,\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"model\", model),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred_proba = pipe.predict_proba(X_val)[:, 1]\n",
    "    score = average_precision_score(y_val, y_pred_proba)\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=200)\n",
    "\n",
    "params = study.best_params\n",
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = encoder_classes[params[\"encoder_type\"]]\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"scaler\", StandardScaler(), num_cols),\n",
    "        (\"encoder\", encoder_classes[params[\"encoder_type\"]], cat_cols),\n",
    "    ]\n",
    ")\n",
    "params.pop(\"encoder_type\")\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", LogisticRegression(**params)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred_proba = pipe.predict_proba(X_val)[:, 1]\n",
    "y_pred = pipe.predict(X_val)\n",
    "\n",
    "metrics, artifacts = get_metrics(\"logistic_regression\", y_pred, y_pred_proba, y_val)\n",
    "\n",
    "with mlflow.start_run(run_name=\"logistic_regression\") as run:\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=pipe,\n",
    "        artifact_path=\"logistic_regression\",\n",
    "        input_example=X,\n",
    "        registered_model_name=\"logistic_regression\",\n",
    "    )\n",
    "    mlflow.log_artifacts(artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def to_category(data):\n",
    "    data = copy.deepcopy(data)\n",
    "    for c in data.columns:\n",
    "        col_type = data[c].dtype\n",
    "        if (\n",
    "            col_type == \"object\"\n",
    "            or col_type.name == \"category\"\n",
    "            or col_type.name == \"datetime64[ns]\"\n",
    "            or col_type.name == \"string\"\n",
    "            or col_type == \"string\"\n",
    "        ):\n",
    "            data[c] = data[c].astype(\"category\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "def get_best_threshold(y_true, y_pred):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    best_threshold = thresholds[best_idx]\n",
    "    best_f1 = f1_scores[best_idx]\n",
    "    return best_f1, best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    with mlflow.start_run(nested=True):\n",
    "        params = {\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 5, 20),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0, step=0.05),\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 200, step=10),\n",
    "            \"eta\": trial.suggest_float(\"eta\", 0.00001, 0.1, log=True),\n",
    "            \"reg_alpha\": trial.suggest_int(\"reg_alpha\", 1, 50),\n",
    "            \"reg_lambda\": trial.suggest_int(\"reg_lambda\", 1, 50),\n",
    "            \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 2, 20),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.1, 1.0),\n",
    "        }   \n",
    "        model = XGBClassifier(enable_categorical=True, random_state=42, **params)\n",
    "\n",
    "        model.fit(to_category(X_train), y_train)\n",
    "        y_pred_proba = model.predict_proba(to_category(X_val))[:, 1]\n",
    "        score = average_precision_score(y_val, y_pred_proba)\n",
    "\n",
    "        f1, threshold = get_best_threshold(y_val, y_pred_proba)\n",
    "\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_param(\"threshold\", threshold)\n",
    "        mlflow.log_metric(\"AP\", score)\n",
    "        mlflow.log_metric(\"F1\", f1)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"XGB best threshold\") as run:\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=200)\n",
    "    params = study.best_params\n",
    "\n",
    "    model = XGBClassifier(enable_categorical=True, random_state=42, **params)\n",
    "\n",
    "    model.fit(to_category(X_train), y_train)\n",
    "    y_pred_proba = model.predict_proba(to_category(X_val))[:, 1]\n",
    "\n",
    "    ap = average_precision_score(y_val, y_pred_proba)\n",
    "    f1, threshold = get_best_threshold(y_val, y_pred_proba)\n",
    "    y_pred = np.where(y_pred_proba > threshold, 1, 0)\n",
    "    metrics = {\"AP\": ap, \"F1\": f1}\n",
    "\n",
    "    pr_curve = PrecisionRecallDisplay.from_predictions(\n",
    "        y_val, y_pred_proba, plot_chance_level=True\n",
    "    ).figure_\n",
    "    cm = ConfusionMatrixDisplay.from_predictions(y_val, y_pred).figure_\n",
    "\n",
    "    mlflow.log_figure(pr_curve, \"pr_curve.png\")\n",
    "    mlflow.log_figure(cm, \"confusion_matrix.png\")\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_param(\"threshold\", threshold)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.xgboost.log_model(\n",
    "        xgb_model=model,\n",
    "        artifact_path=\"XGBClassifier\",\n",
    "        input_example=to_category(X_val),\n",
    "        model_format=\"ubj\",\n",
    "        registered_model_name=\"XGBClassifier\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
